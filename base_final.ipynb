{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import catboost\n",
    "import lightgbm\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐글 실행용\n",
    "# train = pd.read_csv('../input/playground-series-s3e23/train.csv', index_col='id')\n",
    "# test = pd.read_csv('../input/playground-series-s3e23/test.csv', index_col='id')\n",
    "\n",
    "# 로컬\n",
    "\n",
    "df_train = pd.read_csv(\"./playground-series-s3e23/train.csv\", index_col=\"id\")\n",
    "df_test = pd.read_csv(\"./playground-series-s3e23/test.csv\", index_col=\"id\")\n",
    "df_original = pd.read_csv(\"./software-defect-prediction/jm1.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing 추가코드\n",
    "## -------------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original 과  train 을 합치는 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"uniq_Op\", \"uniq_Opnd\", \"total_Op\", \"total_Opnd\", \"branchCount\"]\n",
    "\n",
    "for col in columns:\n",
    "    df_original[col][df_original[col] == \"?\"] = np.nan\n",
    "    df_original[col] = df_original[col].astype(float)\n",
    "\n",
    "\n",
    "df_train = pd.concat([df_train, df_original], ignore_index=True)\n",
    "df_train = df_train.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['defects'] = df_train['defects'].astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iqr outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outlier_detection(data):\n",
    "\n",
    "    q1, q3 = np.percentile(data, [25, 75])\n",
    "\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    threshold = iqr * 1.5\n",
    "    outliers = [x for x in data if x < q1 - threshold or x > q3 + threshold]\n",
    "\n",
    "    data_filtered = data[~np.isin(data, outliers)]\n",
    "\n",
    "    return data_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "  iqr_outlier_detection(df_train[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['defects'] = df_train.defects.astype(int)\n",
    "feat_list = list(set(df_train.columns) - set(['defects']))\n",
    "target = 'defects'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['l']  = 1.0 - df_test['l']\n",
    "df_train['l'] = 1.0 - df_train['l']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feat(X):\n",
    "    df = X.copy()\n",
    "    df[\"mean_bnv\"] = (df[\"n\"] + df[\"v\"] + df[\"b\"]) / 3\n",
    "    df[\"mean_uniqOpOpend\"] = (df[\"uniq_Op\"] + df[\"uniq_Opnd\"]) / 2\n",
    "    df[\"mean_totOpOpend\"] = (df[\"total_Op\"] + df[\"total_Opnd\"]) / 2\n",
    "    df[\"mean_brcntvg\"] = (df[\"branchCount\"] + df[\"v(g)\"]) / 2\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = add_feat(df_train)\n",
    "df_test = add_feat(df_test)\n",
    "\n",
    "### HERE ###############\n",
    "df_train.dropna(axis=0,inplace=True)\n",
    "### HERE ###############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(n_quantiles=1000, output_distribution='uniform', random_state=0)\n",
    "qt.fit(df_train[feat_list])\n",
    "\n",
    "tmp_train = pd.DataFrame(qt.transform(df_train[feat_list]))\n",
    "tmp_train.columns = feat_list\n",
    "tmp_train[target] = df_train[target]\n",
    "df_train = tmp_train\n",
    "df_test = pd.DataFrame(qt.transform(df_test[feat_list]))\n",
    "df_test.columns = feat_list\n",
    "\n",
    "feat_list = list(set(df_train.columns.tolist()) - set([target]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0) if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climbing Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing(x, y, x_test):\n",
    "\n",
    "    # Evaluating oof predictions\n",
    "    scores = {}\n",
    "    for col in x.columns:\n",
    "        scores[col] = roc_auc_score(y, x[col])\n",
    "\n",
    "    # Sorting the model scores\n",
    "    scores = {k: v for k, v in sorted(scores.items(), key = lambda item: item[1], reverse = True)}\n",
    "\n",
    "    # Sort oof_df and test_preds\n",
    "    x = x[list(scores.keys())]\n",
    "    x_test = x_test[list(scores.keys())]\n",
    "\n",
    "    STOP = False\n",
    "    current_best_ensemble = x.iloc[:,0]\n",
    "    current_best_test_preds = x_test.iloc[:,0]\n",
    "    MODELS = x.iloc[:,1:]\n",
    "    weight_range = np.arange(-0.5, 0.71, 0.01)\n",
    "    history = [roc_auc_score(y, current_best_ensemble)]\n",
    "    j = 0\n",
    "    while not STOP:\n",
    "        j += 1\n",
    "        potential_new_best_cv_score = roc_auc_score(y, current_best_ensemble)\n",
    "        k_best, wgt_best = None, None\n",
    "        for k in MODELS:\n",
    "            for wgt in weight_range:\n",
    "                potential_ensemble = (1 - wgt) * current_best_ensemble + wgt * MODELS[k]\n",
    "                cv_score = roc_auc_score(y, potential_ensemble)\n",
    "                if cv_score > potential_new_best_cv_score:\n",
    "                    potential_new_best_cv_score = cv_score\n",
    "                    k_best, wgt_best = k, wgt\n",
    "\n",
    "        if k_best is not None:\n",
    "            current_best_ensemble = (1 - wgt_best) * current_best_ensemble + wgt_best * MODELS[k_best]\n",
    "            current_best_test_preds = (1 - wgt_best) * current_best_test_preds + wgt_best * x_test[k_best]\n",
    "            MODELS.drop(k_best, axis = 1, inplace = True)\n",
    "            if MODELS.shape[1] == 0:\n",
    "                STOP = True\n",
    "            history.append(potential_new_best_cv_score)\n",
    "        else:\n",
    "            STOP = True\n",
    "\n",
    "    hill_ens_pred_1 = current_best_ensemble\n",
    "    hill_ens_pred_2 = current_best_test_preds\n",
    "\n",
    "    return [hill_ens_pred_1, hill_ens_pred_2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 43\n",
    "\n",
    "lgb_params0 = {\n",
    "    \"objective\": 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'dart',\n",
    "     \"n_estimators\": 1000,\n",
    "     \"max_depth\": 7,\n",
    "     \"learning_rate\":0.03,\n",
    "     \"num_leaves\": 50,\n",
    "     \"reg_alpha\":3,\n",
    "     \"reg_lambda\": 3,\n",
    "     \"subsample\": 0.7,\n",
    "     'device': 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "     \"colsample_bytree\": 0.7\n",
    "}\n",
    "\n",
    "lgb_params1 = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'dart',\n",
    "    'random_state': 42,\n",
    "    'colsample_bytree': 0.50,\n",
    "    'subsample': 0.70,\n",
    "    'learning_rate': 0.0625,\n",
    "    'max_depth': -1,\n",
    "    'n_estimators': 1000,\n",
    "    'num_leaves': 20,\n",
    "    'reg_alpha': 0.0001,\n",
    "    'reg_lambda': 2.0,\n",
    "    'verbose': -1,\n",
    "    'device': 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    'random_state': random_state,\n",
    "}\n",
    "\n",
    "lgb_params2 = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 42,\n",
    "    'colsample_bytree': 0.50,\n",
    "    'subsample': 0.70,\n",
    "    'learning_rate': 0.0625,\n",
    "    'max_depth': -1,\n",
    "    'n_estimators': 1000,\n",
    "    'num_leaves': 20,\n",
    "    'reg_alpha': 0.0001,\n",
    "    'reg_lambda': 2.0,\n",
    "    'verbose': -1,\n",
    "    'device': 'gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    'random_state': random_state,\n",
    "}\n",
    "\n",
    "xgb_optuna0 = {\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.01752354328845971,\n",
    "    'booster': 'gbtree',\n",
    "    'lambda': 0.08159630121074074,\n",
    "    'alpha': 0.07564858712175693,\n",
    "    'subsample': 0.5065979400270813,\n",
    "    'colsample_bytree': 0.6187340851873067,\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 5,\n",
    "    'eta': 0.2603059902806757,\n",
    "    'gamma': 0.6567360773618207,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': random_state\n",
    "}\n",
    "\n",
    "xgb_params0 = {\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.09641232707445854,\n",
    "    'booster': 'gbtree',\n",
    "    'lambda': 4.666002223704784,\n",
    "    'alpha': 3.708175990751336,\n",
    "    'subsample': 0.6100174145229473,\n",
    "    'colsample_bytree': 0.5506821152321051,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 3,\n",
    "    'eta': 1.740374368661041,\n",
    "    'gamma': 0.007427363662926455,\n",
    "    'grow_policy': 'depthwise',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'verbosity': 0,\n",
    "    'random_state': random_state,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'tree_method': 'hist',\n",
    "}\n",
    "\n",
    "xgb_params1 = {\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.012208383405206188,\n",
    "    'booster': 'gbtree',\n",
    "    'lambda': 0.009968756668882757,\n",
    "    'alpha': 0.02666266827121168,\n",
    "    'subsample': 0.7097814108897231,\n",
    "    'colsample_bytree': 0.7946945784285216,\n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 4,\n",
    "    'eta': 0.5480204506554545,\n",
    "    'gamma': 0.8788654128774149,\n",
    "    'scale_pos_weight': 4.71,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'early_stopping_rounds': 100,\n",
    "    'verbosity': 0,\n",
    "    'random_state': random_state,\n",
    "    'tree_method': 'hist',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xgb_params2 = {\n",
    "    'n_estimators': 10000,\n",
    "    'colsample_bytree': 0.5646751146007976,\n",
    "    'gamma': 7.788727238356553e-06,\n",
    "    'learning_rate': 0.1419865761603358,\n",
    "    'max_bin': 824,\n",
    "    'min_child_weight': 1,\n",
    "    'random_state': 811996,\n",
    "    'reg_alpha': 1.6259583347890365e-07,\n",
    "    'reg_lambda': 2.110691851528507e-08,\n",
    "    'subsample': 0.879020578464637,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'max_depth': 3,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': 0,\n",
    "    'random_state': random_state,\n",
    "    'tree_method': 'hist',\n",
    "   # 'scale_pos_weight': scale_pos_weight\n",
    "}\n",
    "\n",
    "xgb_params3 = {\n",
    "    'n_estimators': 10000,\n",
    "    'random_state': random_state,\n",
    "    'colsample_bytree': 0.4836462317215041,\n",
    "    'eta': 0.05976752607337169,\n",
    "    'gamma': 1,\n",
    "    'lambda': 0.2976432557733288,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'n_estimators': 550,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'objective': 'binary:logistic',\n",
    "    'scale_pos_weight': 4.260162886376033,\n",
    "    'subsample': 0.7119282378433924,\n",
    "    'tree_method': 'hist',\n",
    "}\n",
    "\n",
    "xgb_params4 = {\n",
    "    'n_estimators': 10000,\n",
    "    'colsample_bytree': 0.8757972257439255,\n",
    "    'gamma': 0.11135738771999848,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 3,\n",
    "    'reg_alpha': 0.4833998914998038,\n",
    "    'reg_lambda': 0.006223568555619563,\n",
    "    'scale_pos_weight': 8,\n",
    "    'subsample': 0.7056434340275685,\n",
    "    'random_state': random_state,\n",
    "    'tree_method': 'hist',\n",
    "    'early_stopping_rounds': 100,\n",
    "}\n",
    "\n",
    "xgb_params5 = {\n",
    "    'n_estimators': 10000,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 2.934487833919741,\n",
    "    'learning_rate': 0.11341944575807082,\n",
    "    'subsample': 0.9045063514419968,\n",
    "    'gamma': 0.4329153382843715,\n",
    "    'colsample_bytree': 0.38872702868412506,\n",
    "    'colsample_bylevel': 0.8321880031718571,\n",
    "    'colsample_bynode': 0.802355707802605,\n",
    "    'random_state': random_state,\n",
    "    'tree_method': 'hist',\n",
    "    'early_stopping_rounds': 100,\n",
    "}\n",
    "\n",
    "xgb_base = {\n",
    "    'n_estimators': 1000,\n",
    "    'verbosity': 0,\n",
    "    'random_state': random_state,\n",
    "}\n",
    "\n",
    "xgb_params6 = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'colsample_bytree': 0.7,\n",
    "    'gamma': 2,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 10,\n",
    "    'n_estimators': 10000,\n",
    "    'subsample':0.7,\n",
    "    'random_state': random_state,\n",
    "    'tree_method': 'hist',\n",
    "    'early_stopping_rounds': 100,\n",
    "}\n",
    "\n",
    "cat_params0 = {\n",
    "    'iterations': 10000,\n",
    "    'eval_metric': 'AUC',\n",
    "    'loss_function': 'Logloss',\n",
    "    'task_type': 'GPU' if torch.cuda.is_available() else 'CPU',\n",
    "    'early_stopping_rounds': 100,\n",
    "    'auto_class_weights': 'Balanced'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "class BaseModel(metaclass=ABCMeta):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, trn_x, trn_y, val_x, val_y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomForestModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, trn_x, trn_y, val_x, val_y):\n",
    "        self.model = RandomForestClassifier(n_estimators = 1000,\n",
    "                                            class_weight='balanced',\n",
    "                                           max_depth = 7,\n",
    "                                           min_samples_split = 15,\n",
    "                                           min_samples_leaf = 10)\n",
    "        self.model.fit(trn_x, trn_y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "class HistGradientBoostingModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = None\n",
    "\n",
    "    def train(self, trn_x, trn_y, val_x, val_y):\n",
    "        self.model = HistGradientBoostingClassifier(l2_regularization = 0.01,\n",
    "                                             early_stopping = True,\n",
    "                                             learning_rate = 0.01,\n",
    "                                             max_iter = 1000,\n",
    "                                             max_depth = 5,\n",
    "                                             max_bins = 255,\n",
    "                                             min_samples_leaf = 15,\n",
    "                                             max_leaf_nodes = 10)\n",
    "        self.model.fit(trn_x, trn_y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "class LGBMModel(BaseModel):\n",
    "    def __init__(self, **config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = LGBMClassifier(**self.config)\n",
    "\n",
    "    def train(self, trn_x, trn_y, val_x, val_y):\n",
    "        self.model.fit(trn_x, trn_y, eval_set=(val_x, val_y), verbose=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "\n",
    "class XGBModel(BaseModel):\n",
    "    def __init__(self, **config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = XGBClassifier(**self.config)\n",
    "\n",
    "    def train(self, trn_x, trn_y, val_x, val_y):\n",
    "        self.model.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], verbose=0)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "class CatBoostModel(BaseModel):\n",
    "    def __init__(self, **config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = CatBoostClassifier(**self.config)\n",
    "\n",
    "    def train(self, trn_x, trn_y, val_x, val_y):\n",
    "        self.model.fit(trn_x, trn_y, eval_set=(val_x, val_y), verbose=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "def train(X_train, y_train, X_test, models, n_folds=10):\n",
    "\n",
    "    valid_preds, test_preds = dict(), dict()\n",
    "    hill_ens_preds =  list()\n",
    "\n",
    "    sk = RepeatedStratifiedKFold(n_splits = n_folds, n_repeats = 1, random_state = 42)\n",
    "    for i, (trn_idx, val_idx) in enumerate(sk.split(X_train, y_train)):\n",
    "\n",
    "        trn_x, trn_y = X_train.iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "        val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        print('----------------------------------------------------------')\n",
    "        ens_pred_1 = np.zeros((val_x.shape[0], ))\n",
    "        ens_pred_2 = np.zeros((X_test.shape[0], ))\n",
    "\n",
    "        for idx, model in enumerate(models):\n",
    "            print(\"model\", model)\n",
    "            model.train(trn_x, trn_y, val_x, val_y)\n",
    "\n",
    "            ens_pred_1 = model.predict(val_x)\n",
    "            ens_pred_2 = model.predict(X_test)\n",
    "\n",
    "            print(f\"ROC: {roc_auc_score(val_y, ens_pred_1)}\")\n",
    "\n",
    "            valid_preds[f'model_{idx}'] = ens_pred_1\n",
    "            test_preds[f'model_{idx}'] = ens_pred_2\n",
    "\n",
    "        ens_pred_1 = np.mean(list(valid_preds.values()), axis=0)\n",
    "        ens_pred_2 = np.mean(list(test_preds.values()), axis=0)\n",
    "\n",
    "\n",
    "        ens_score_fold = roc_auc_score(val_y, ens_pred_1)\n",
    "        print('Fold', i, '==> Average Ensemble oof ROC-AUC score is ==>', ens_score_fold)\n",
    "\n",
    "        ############################\n",
    "        ## Hill Climbing Ensemble ##\n",
    "        ############################\n",
    "\n",
    "        x = pd.DataFrame(valid_preds)\n",
    "        y = val_y\n",
    "        x_test = pd.DataFrame(test_preds)\n",
    "\n",
    "        hill_results = hill_climbing(x, y, x_test)\n",
    "        hill_ens_score_fold = roc_auc_score(y, hill_results[0])\n",
    "\n",
    "        # test preds\n",
    "        hill_ens_preds.append(hill_results[1])\n",
    "\n",
    "        print('Fold', i, '==> Hill Climbing Ensemble oof ROC-AUC score is ==>', hill_ens_score_fold)\n",
    "\n",
    "    return hill_ens_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['defects'],axis=1)\n",
    "y_train = df_train['defects']\n",
    "X_test = df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train = df_train[feat_list], df_test[feat_list], df_train[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_v1 = [XGBModel(**xgb_optuna0),\n",
    "             XGBModel(**xgb_params3),\n",
    "             XGBModel(**xgb_params6),\n",
    "             LGBMModel(**lgb_params0),\n",
    "             LGBMModel(**lgb_params1),\n",
    "             LGBMModel(**lgb_params2),\n",
    "             HistGradientBoostingModel(),\n",
    "             CatBoostModel(**cat_params0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "model <__main__.XGBModel object at 0x29c32f410>\n",
      "ROC: 0.7804953896185315\n",
      "model <__main__.XGBModel object at 0x2992f4dd0>\n",
      "ROC: 0.7755844114488604\n",
      "model <__main__.XGBModel object at 0x29c32e790>\n",
      "ROC: 0.7812162341078478\n",
      "model <__main__.LGBMModel object at 0x29b646b10>\n"
     ]
    }
   ],
   "source": [
    "hill_ens_preds = train(X_train, y_train, X_test, models_v1, n_folds=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hill climbing\n",
    "# 캐글 제출용\n",
    "# submission = pd.read_csv('/kaggle/input/playground-series-s3e23/sample_submission.csv')\n",
    "\n",
    "# 로컬\n",
    "submission = pd.read_csv('./playground-series-s3e23/sample_submission.csv')\n",
    "\n",
    "submission['defects'] = np.mean(hill_ens_preds, axis=0)\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "42AI-sucho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
